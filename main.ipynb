{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 함수\n",
    "\n",
    "* 코드를 수정하지 말고 실행만 하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 특정 파일명으로 sample과 reference 이미지를 읽어오는 함수\n",
    "def load_single_sample_and_reference(filename, sample_folder, reference_folder):\n",
    "    sample_path = os.path.join(sample_folder, filename)\n",
    "    reference_path = os.path.join(reference_folder, filename)\n",
    "\n",
    "    sample_img = cv2.imread(sample_path)\n",
    "    reference_img = cv2.imread(reference_path)\n",
    "\n",
    "    if sample_img is None:\n",
    "        raise ValueError(f\"Sample image not found: {sample_path}\")\n",
    "    if reference_img is None:\n",
    "        raise ValueError(f\"Reference image not found: {reference_path}\")\n",
    "\n",
    "    return sample_img, reference_img\n",
    "\n",
    "# 2. sample과 reference를 시각화하는 함수\n",
    "def visualize_sample_and_reference(sample_img, reference_img, filename=None):\n",
    "    # BGR -> RGB 변환 (OpenCV는 BGR로 읽기 때문)\n",
    "    sample_img_rgb = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
    "    reference_img_rgb = cv2.cvtColor(reference_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(sample_img_rgb)\n",
    "    plt.title('Sample Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(reference_img_rgb)\n",
    "    plt.title('Reference Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    if filename:\n",
    "        plt.suptitle(filename, fontsize=16)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 4. 성능 평가 (Accuracy)\n",
    "def evaluate_accuracy(gt_df, pred_df):\n",
    "    # --- 데이터 검증 ---\n",
    "    # 같은 filename에 대해 class가 여러 개 있는지 확인\n",
    "    pred_multi_class = pred_df.groupby('filename')['class'].nunique()\n",
    "    if (pred_multi_class > 1).any():\n",
    "        conflict_files = pred_multi_class[pred_multi_class > 1].index.tolist()\n",
    "        raise ValueError(f\"Prediction 데이터 오류: 다음 파일들은 여러 class를 가지고 있습니다: {conflict_files}\")\n",
    "\n",
    "    # gt_df 기준으로 left join\n",
    "    merged_df = pd.merge(gt_df[['filename','class']], pred_df[['filename','class']], on='filename', how='left', suffixes=('_gt', '_pred'))\n",
    "\n",
    "    # prediction이 없는 경우 class_pred를 'None'으로 처리\n",
    "    merged_df['class_pred'] = merged_df['class_pred'].fillna('None')\n",
    "\n",
    "    # 전체 accuracy 계산 (gt 기준)\n",
    "    correct = (merged_df['class_gt'] == merged_df['class_pred']).sum()\n",
    "    total = len(merged_df)\n",
    "    overall_accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "    # class별 accuracy 계산\n",
    "    class_acc = {}\n",
    "    classes = merged_df['class_gt'].unique()\n",
    "\n",
    "    for cls in sorted(classes):\n",
    "        cls_df = merged_df[merged_df['class_gt'] == cls]\n",
    "        correct_cls = (cls_df['class_gt'] == cls_df['class_pred']).sum()\n",
    "        total_cls = len(cls_df)\n",
    "        acc_cls = correct_cls / total_cls if total_cls > 0 else 0\n",
    "        class_acc[cls] = acc_cls\n",
    "\n",
    "    return overall_accuracy, class_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답 파일 읽어오기\n",
    "\n",
    "* gt_df 데이터 프레임에는 아래와 같은 불량에 대한 정답 정보가 들어 있습니다.\n",
    "  * filename: 이미지 파일명\n",
    "  * class: 불량의 종류 (6가지 중 1가지에 해당)\n",
    "      * missing_hole\n",
    "      * mouse_bite\n",
    "      * open_circuit\n",
    "      * short\n",
    "      * spur\n",
    "      * spurious_copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더 경로 설정\n",
    "sample_folder = 'sampled_dataset/noisy_samples/'\n",
    "reference_folder = 'sampled_dataset/reference/'\n",
    "gt_csv_path = 'sampled_dataset/cropped_labels.csv'\n",
    "\n",
    "# 1. GT 파일 읽기\n",
    "gt_df = pd.read_csv(gt_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 각 불량 유형에 대한 분류 기준 정의\n",
    "def classify_defect_with_reference_comparison(mean_val, ref_mean_val, eccentricity, max_axis, min_axis, solidity, \n",
    "                                              ratio, ref_img, mask, contour, corner_count, rectangularity):\n",
    "    # 1-1. 불량 밝기 차이 계산: 현재 불량 영역 밝기 - 기준 이미지 같은 영역 밝기\n",
    "    brightness_diff = mean_val - ref_mean_val\n",
    "\n",
    "    # 1-2. 밝기 차이에 따라 불량 유형 1차 분류\n",
    "    if brightness_diff <= 0:  # 어두운 영역 (빠진 불량)\n",
    "\n",
    "        # 2차 분류: 형태적 특징 및 주변 밝기 등을 바탕으로 불량 유형 구체화\n",
    "        # 1-2-1. 불량이 원형에 가깝고, 형태적 비율이 중간 수준일 때 → missing_hole\n",
    "        if eccentricity < 0.55 and 0.2 < ratio < 0.9:\n",
    "            return 'missing_hole'\n",
    "\n",
    "        # 1-2-2. 이전 조건에서 제외된 불량 중, 밝기 비율이 높고 사각형 유사도가 낮으면 → mouse_bite\n",
    "        elif ratio > 0.4 and rectangularity < 0.8:\n",
    "            return 'mouse_bite'\n",
    "\n",
    "        # 1-2-3. 위 두 조건을 만족하지 못하면 → open_circuit\n",
    "        else:\n",
    "            return 'open_circuit'\n",
    "\n",
    "    # 1-3. 밝기 차이가 양수일 경우 (밝은 영역: 추가된 불량)\n",
    "    elif brightness_diff > 0:\n",
    "        # 1-3-1. 불량 길이가 작고 밝기 비율이 일정 범위일 때 → short\n",
    "        if max_axis < 50 and 0.3 < ratio < 1:\n",
    "            return 'short'\n",
    "        else:\n",
    "            # 1-3-2. 주변 밝기 평균을 이용해 spur와 spurious_copper를 세부 구분.\n",
    "            # spur는 주변 회로가 있어서 밝기 값이 높게 나타나고, spurious_copper는 실제 회로와 떨어진 구조물이므로 주변 밝기값이 낮게 나타남\n",
    "            kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "            dilated = cv2.dilate(mask, kernel, iterations=3)\n",
    "            border_mask = cv2.subtract(dilated, mask)\n",
    "            ref_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)\n",
    "            border_mean = cv2.mean(ref_gray, mask=border_mask)[0]\n",
    "\n",
    "            # 1-3-3. 주변 밝기값이 높으면 spur, 아니면 spurious_copper\n",
    "            if border_mean > 40:\n",
    "                return 'spur'  \n",
    "            else:\n",
    "                return 'spurious_copper'  \n",
    "\n",
    "    # 1-4. 위 모든 분류 조건에서 실패한 경우 → 분류 실패로 간주하고 None 반환\n",
    "    print('분류 실패')\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# 2. SIFT 매칭이 1차 시도에서 실패한 경우, 이미지 대비를 향상시켜 매칭 성능을 높이기 위한 보조 함수 정의\n",
    "def enhance_image_contrast(gray_img, method='clahe'):\n",
    "\n",
    "    if method == 'clahe':\n",
    "        # CLAHE : 지역적으로 대비를 조절하여 과도한 밝기/어둠을 방지\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        return clahe.apply(gray_img)\n",
    "    \n",
    "    elif method == 'hist_eq':\n",
    "        # 히스토그램 균등화 : 전체 이미지의 픽셀 분포를 균일하게 만들어 대비를 향상시킴\n",
    "        return cv2.equalizeHist(gray_img)\n",
    "    \n",
    "    elif method == 'gamma':\n",
    "        # 감마 보정 : 픽셀 값에 감마 함수를 적용하여 밝기를 비선형적으로 조정함.\n",
    "        gamma = 0.8\n",
    "        inv_gamma = 1.0 / gamma\n",
    "        table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "        return cv2.LUT(gray_img, table)\n",
    "    \n",
    "    else:\n",
    "        return gray_img\n",
    "\n",
    "\n",
    "\n",
    "# 3. SIFT 기반 이미지 정합 함수 : 입력 이미지(sample_img)를 기준 이미지(ref_img)에 정합시키기 위해 SIFT 특징점 기반으로 매칭 수행\n",
    "def enhanced_sift_matching(sample_img, ref_img, filename):\n",
    "    # 3-1. 두 이미지를 그레이스케일로 변환\n",
    "    gray_s = cv2.cvtColor(sample_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_r = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    detector = cv2.SIFT_create()\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # 3-2. 원본 이미지에서 SIFT 특징점 및 기술자 추출\n",
    "    kp_s, des_s = detector.detectAndCompute(gray_s, None)\n",
    "    kp_r, des_r = detector.detectAndCompute(gray_r, None)\n",
    "\n",
    "    # 3-3. 첫 번째 시도: 기본 SIFT 매칭 시도\n",
    "    if des_s is not None and des_r is not None:\n",
    "        try:\n",
    "            matches = bf.knnMatch(des_s, des_r, k=2)\n",
    "            good = [m for m, n in matches if m.distance < 0.9 * n.distance]\n",
    "\n",
    "            # 3-4. 좋은 매칭이 3개 이상일 경우 Affine 변환 적용\n",
    "            if len(good) >= 3:\n",
    "                src = np.float32([kp_s[m.queryIdx].pt for m in good]).reshape(-1, 2)\n",
    "                dst = np.float32([kp_r[m.trainIdx].pt for m in good]).reshape(-1, 2)\n",
    "                M, _ = cv2.estimateAffine2D(src, dst, method=cv2.RANSAC, ransacReprojThreshold=4.0)\n",
    "\n",
    "                if M is not None:\n",
    "                    h_r, w_r = ref_img.shape[:2]\n",
    "                    warped = cv2.warpAffine(sample_img, M, (w_r, h_r))\n",
    "                    return warped\n",
    "        except Exception as e:\n",
    "            print(f\"1차 실패: {e}\")\n",
    "\n",
    "    # 3-5. 두 번째 시도: 다양한 대비 향상 기법을 적용하여 SIFT 매칭 시도\n",
    "    contrast_methods = ['clahe', 'hist_eq', 'gamma']\n",
    "\n",
    "    for contrast_method in contrast_methods:\n",
    "        try:\n",
    "            enhanced_s = enhance_image_contrast(gray_s, contrast_method)\n",
    "            enhanced_r = enhance_image_contrast(gray_r, contrast_method)\n",
    "\n",
    "            kp_s, des_s = detector.detectAndCompute(enhanced_s, None)\n",
    "            kp_r, des_r = detector.detectAndCompute(enhanced_r, None)\n",
    "\n",
    "            if des_s is not None and des_r is not None:\n",
    "                matches = bf.knnMatch(des_s, des_r, k=2)\n",
    "                good = [m for m, n in matches if m.distance < 0.85 * n.distance]\n",
    "\n",
    "                if len(good) >= 3:\n",
    "                    src = np.float32([kp_s[m.queryIdx].pt for m in good]).reshape(-1, 2)\n",
    "                    dst = np.float32([kp_r[m.trainIdx].pt for m in good]).reshape(-1, 2)\n",
    "                    M, _ = cv2.estimateAffine2D(src, dst, method=cv2.RANSAC, ransacReprojThreshold=5.0)\n",
    "\n",
    "                    if M is not None:\n",
    "                        h_r, w_r = ref_img.shape[:2]\n",
    "                        warped = cv2.warpAffine(sample_img, M, (w_r, h_r))\n",
    "                        return warped\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"2차 실패 ({contrast_method}): {e}\")\n",
    "\n",
    "    # 3-6. 세 번째 시도: 이미지 크기 유사성 기반 단순 리사이즈 적용\n",
    "    try:\n",
    "        h_r, w_r = ref_img.shape[:2]\n",
    "        h_s, w_s = sample_img.shape[:2]\n",
    "\n",
    "        if abs(h_r - h_s) < 50 and abs(w_r - w_s) < 50:\n",
    "            warped = cv2.resize(sample_img, (w_r, h_r))\n",
    "            return warped\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 3-7. 모든 정합 시도가 실패한 경우 None 반환\n",
    "    return None\n",
    "\n",
    "##### 메인 코드 #####\n",
    "def run_enhanced_inspection():\n",
    "  \n",
    "    preds = []        # 최종 예측 결과 저장 리스트\n",
    "    failed_files = [] # 정합 실패 파일 저장 리스트\n",
    "\n",
    "    # 1-1. (gt_df)에서 각 이미지 순차 처리\n",
    "    for filename in tqdm(gt_df['filename']):\n",
    "        try:\n",
    "            # 1-2. 샘플 이미지와 기준 이미지 불러오기\n",
    "            sample_img, ref_img = load_single_sample_and_reference(filename, sample_folder, reference_folder)\n",
    "\n",
    "            # 1-3. SIFT 기반 이미지 정합 수행\n",
    "            warped = enhanced_sift_matching(sample_img, ref_img, filename)\n",
    "\n",
    "            # 1-4. 모든 정합 시도 실패 시, 실패 파일 리스트에 기록하고 건너뛰기\n",
    "            if warped is None:\n",
    "                failed_files.append(filename)\n",
    "                continue\n",
    "\n",
    "            # 2-1. 정합된 이미지와 기준 이미지 간 차이 계산 (배경 영역 제외)\n",
    "            mask_valid = np.any(warped != 0, axis=2)\n",
    "            diff_full = cv2.absdiff(ref_img, warped)\n",
    "            diff = np.zeros_like(diff_full)\n",
    "            diff[mask_valid] = diff_full[mask_valid]\n",
    "\n",
    "            # 2-2. 차이 이미지 전처리: 회색조 변환 → 이진화 → 잡음 제거\n",
    "            gray_d = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "            _, thr = cv2.threshold(gray_d, 10, 255, cv2.THRESH_BINARY)\n",
    "            thr = cv2.morphologyEx(thr, cv2.MORPH_OPEN, np.ones((4, 3), np.uint8))\n",
    "\n",
    "            # 2-3. 윤곽선(변화 영역) 추출 후 면적 기준(≥70px) 필터링\n",
    "            contours, _ = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours = [c for c in contours if cv2.contourArea(c) >= 70]\n",
    "\n",
    "            # 3-1. 차이 영역 미발견 시 RGB 채널별 추가 탐색 시도\n",
    "            if not contours:\n",
    "                # 3-2. 각 RGB 채널별로 개별 처리\n",
    "                channels_to_try = [\n",
    "                    (\"Blue_channel\", diff[:, :, 0]),\n",
    "                    (\"Green_channel\", diff[:, :, 1]),\n",
    "                    (\"Red_channel\", diff[:, :, 2])\n",
    "                ]\n",
    "\n",
    "                for channel_name, channel_img in channels_to_try:\n",
    "                    _, thr = cv2.threshold(channel_img, 8, 255, cv2.THRESH_BINARY)\n",
    "                    thr = cv2.morphologyEx(thr, cv2.MORPH_OPEN, np.ones((4, 3), np.uint8))\n",
    "\n",
    "                    temp_contours, _ = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    temp_contours = [c for c in temp_contours if cv2.contourArea(c) >= 60]\n",
    "\n",
    "                    # 3-3. 윤곽선 발견 시 contours 업데이트 후 루프 종료\n",
    "                    if temp_contours:\n",
    "                        contours = temp_contours\n",
    "                        break\n",
    "\n",
    "            # 3-4. 추가 탐색 후에도 변화 영역 없으면 실패 처리\n",
    "            if not contours:\n",
    "                failed_files.append(filename)\n",
    "                continue\n",
    "\n",
    "            # 4-1. 이미지 중심에 가장 가까운 컨투어 선택\n",
    "            h, w = gray_d.shape\n",
    "            center_x, center_y = w / 2.0, h / 2.0\n",
    "\n",
    "            def center_distance(cnt):\n",
    "                M = cv2.moments(cnt)\n",
    "                if M['m00'] == 0:\n",
    "                    return float('inf')\n",
    "                cx = M['m10'] / M['m00']\n",
    "                cy = M['m01'] / M['m00']\n",
    "                return (cx - center_x) ** 2 + (cy - center_y) ** 2\n",
    "\n",
    "            c = min(contours, key=center_distance)\n",
    "\n",
    "            # 5-1. 형태 기반 특징 추출 (외접 최소 사각형, 면적, 둘레, 원형도 등)\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            (w_rec, h_rec) = rect[1]\n",
    "            max_axis = max(w_rec, h_rec)\n",
    "            min_axis = min(w_rec, h_rec)\n",
    "\n",
    "            area = cv2.contourArea(c)\n",
    "            perimeter = cv2.arcLength(c, True)\n",
    "            ratio = 4 * np.pi * area / (perimeter ** 2 + 1e-6)\n",
    "\n",
    "            hull = cv2.convexHull(c)\n",
    "            hull_area = cv2.contourArea(hull)\n",
    "            solidity = area / (hull_area + 1e-6)\n",
    "            corner_count = len(c)\n",
    "\n",
    "            rect_area = w_rec * h_rec\n",
    "            rectangularity = area / (rect_area + 1e-6)\n",
    "\n",
    "            # 5-2. 타원 근사 가능 시 이심률 계산\n",
    "            if len(c) >= 5:\n",
    "                ellipse = cv2.fitEllipse(c)\n",
    "                major, minor = max(ellipse[1]) / 2, min(ellipse[1]) / 2\n",
    "                eccentricity = np.sqrt(1 - (minor / (major + 1e-6)) ** 2)\n",
    "            else:\n",
    "                eccentricity = 1.0\n",
    "\n",
    "            # 6-1. 밝기 기반 특징 추출 (불량 영역 마스크로 영역 밝기 평균 계산)\n",
    "            mask = np.zeros_like(gray_d)\n",
    "            cv2.drawContours(mask, [c], -1, 255, cv2.FILLED)\n",
    "\n",
    "            mean_val = cv2.mean(cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY), mask=mask)[0]\n",
    "            ref_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)\n",
    "            ref_mean_val = cv2.mean(ref_gray, mask=mask)[0]\n",
    "\n",
    "            # 7-1. 추출된 특징을 이용하여 불량 유형 최종 분류\n",
    "            cls = classify_defect_with_reference_comparison(\n",
    "                mean_val, ref_mean_val, eccentricity, max_axis, min_axis,\n",
    "                solidity, ratio, ref_img, mask, c, corner_count, rectangularity\n",
    "            )\n",
    "\n",
    "            # 7-2. 결과를 최종 예측 리스트에 추가\n",
    "            preds.append(cls)\n",
    "\n",
    "        except Exception as e:\n",
    "            # 8-1. 처리 중 예외 발생 시 실패 파일로 기록 후 다음 이미지로 진행\n",
    "            print(f\"[오류] {filename} - {e}\")\n",
    "            failed_files.append(filename)\n",
    "\n",
    "    # 9-1. 모든 이미지 처리 완료 후 최종 예측 결과와 실패 리스트 반환\n",
    "    return preds, failed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 검사 실행 → 결함 분류 결과(preds)와 처리 실패 파일 목록(failed_files) 반환\n",
    "preds, failed_files = run_enhanced_inspection()\n",
    "\n",
    "# 2. 처리에 성공한 파일 목록을 생성해서 gt_df에 매칭하였음 / contour 추출 실패한 파일은 제외하고 평가됨\n",
    "successful_files = [fname for fname in gt_df['filename'] if fname not in failed_files]\n",
    "gt_df = gt_df[gt_df['filename'].isin(successful_files)]\n",
    "\n",
    "# 3. 예측 결과 데이터프레임 생성\n",
    "pred_df = pd.DataFrame({\n",
    "    'filename': successful_files,\n",
    "    'class':    preds\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가 (분류 정확도)\n",
    "\n",
    "* 코드 수정은 하지말고 실행만 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc, class_acc = evaluate_accuracy(gt_df, pred_df)\n",
    "\n",
    "# 전체 Accuracy 출력\n",
    "print(f\"\\n[전체 Accuracy]\")\n",
    "print(f\"Overall Accuracy: {overall_acc * 100:.2f}%\\n\")\n",
    "\n",
    "# 클래스별 Accuracy 출력\n",
    "print(\"[클래스별 Accuracy]\")\n",
    "for cls, acc in sorted(class_acc.items()):\n",
    "    print(f\"Class '{cls}': {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1364422,
     "sourceId": 2266446,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
